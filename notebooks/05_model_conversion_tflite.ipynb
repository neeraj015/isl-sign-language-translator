{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95d8893d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1cdf9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\hp\\AppData\\Local\\Temp\\tmph1y84vea\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\hp\\AppData\\Local\\Temp\\tmph1y84vea\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\hp\\AppData\\Local\\Temp\\tmph1y84vea'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 35), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2570117207792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117212720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117242672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117241616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117248656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117337280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117346784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117347488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117535472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117536176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "âœ… Basic float32 TFLite model saved (no quantization).\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\hp\\AppData\\Local\\Temp\\tmp_2cfsdna\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\hp\\AppData\\Local\\Temp\\tmp_2cfsdna\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\hp\\AppData\\Local\\Temp\\tmp_2cfsdna'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 35), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2570117207792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117212720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117242672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117241616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117248656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117337280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117346784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117347488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117535472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2570117536176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "âœ… Quantized TFLite model saved (dynamic range).\n",
      "\n",
      "ðŸ“¦ Float32 TFLite size: 5012.28 KB\n",
      "ðŸ“¦ Quantized TFLite size: 1265.75 KB\n",
      "ðŸŽ¯ Compression ratio: 3.96\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Imports\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Step 2: Load the trained model\n",
    "model = tf.keras.models.load_model(\"../models/best_model.h5\", compile=False)\n",
    "\n",
    "# Step 3: Convert to TFLite (Basic)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Step 4: Save the TFLite model (basic version)\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "with open(\"../models/model_fp32.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"âœ… Basic float32 TFLite model saved (no quantization).\")\n",
    "\n",
    "# Step 5: Convert to TFLite with Dynamic Range Quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "# Step 6: Save quantized model\n",
    "with open(\"../models/model_quant.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_quant_model)\n",
    "\n",
    "print(\"âœ… Quantized TFLite model saved (dynamic range).\")\n",
    "\n",
    "# Optional: Show size comparison\n",
    "import os\n",
    "fp32_size = os.path.getsize(\"../models/model_fp32.tflite\") / 1024\n",
    "quant_size = os.path.getsize(\"../models/model_quant.tflite\") / 1024\n",
    "\n",
    "print(f\"\\nðŸ“¦ Float32 TFLite size: {fp32_size:.2f} KB\")\n",
    "print(f\"ðŸ“¦ Quantized TFLite size: {quant_size:.2f} KB\")\n",
    "print(\"ðŸŽ¯ Compression ratio:\", round(fp32_size / quant_size, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f1185f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class Index: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\DataScienceProjects\\isl_translator\\isl_env\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# Test the .tflite Model\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load test data\n",
    "X_test = np.load(\"../data/processed/X_test.npy\")\n",
    "\n",
    "# Load TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"../models/model_quant.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Prepare a sample image (batch of 1)\n",
    "img = X_test[0:1].astype(np.float32)\n",
    "\n",
    "# Run inference\n",
    "interpreter.set_tensor(input_details[0]['index'], img)\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# Get predicted class\n",
    "predicted_class = np.argmax(output_data)\n",
    "print(\"Predicted Class Index:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6ce4484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 31\n"
     ]
    }
   ],
   "source": [
    " # Show Class Label\n",
    "\n",
    "import joblib\n",
    "label_encoder = joblib.load(\"../logs/label_encoder.pkl\")\n",
    "class_label = label_encoder.inverse_transform([predicted_class])[0]\n",
    "print(\"Predicted Label:\", class_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1108fc15",
   "metadata": {},
   "source": [
    "Lighter size for mobile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b562d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\hp\\AppData\\Local\\Temp\\tmpglgdl5x2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\hp\\AppData\\Local\\Temp\\tmpglgdl5x2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\hp\\AppData\\Local\\Temp\\tmpglgdl5x2'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 35), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2568391833232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568391805584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568391818608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568391814032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568391916208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568391912688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568392085696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568392086400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568392095376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568392096080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "âœ… Float16 Quantized TFLite model saved.\n"
     ]
    }
   ],
   "source": [
    "# Float16 Quantization (Best for GPU/mobile inference)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load your trained model\n",
    "model = tf.keras.models.load_model(\"../models/best_model.h5\", compile=False)\n",
    "\n",
    "# Create a converter\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Apply float16 quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save to file\n",
    "with open(\"../models/model_fp16.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\" Float16 Quantized TFLite model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ea32246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\hp\\AppData\\Local\\Temp\\tmp4j_pn_ku\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\hp\\AppData\\Local\\Temp\\tmp4j_pn_ku\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\hp\\AppData\\Local\\Temp\\tmp4j_pn_ku'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 35), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2568391833232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568391805584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568391818608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568391814032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568391916208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568391912688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568392085696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568392086400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568392095376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2568392096080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\DataScienceProjects\\isl_translator\\isl_env\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " INT8 Quantized TFLite model saved.\n"
     ]
    }
   ],
   "source": [
    "# Full Integer Quantization (INT8) â€“  maximum compression\n",
    "\n",
    "#  Define Representative Dataset Function\n",
    "import numpy as np\n",
    "\n",
    "X_test = np.load(\"../data/processed/X_test.npy\")\n",
    "\n",
    "def representative_data_gen():\n",
    "    for i in range(100):  # Use ~100 samples for calibration\n",
    "        yield [X_test[i:i+1].astype(np.float32)]\n",
    "\n",
    "\n",
    "#Perform Full INT8 Conversion\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Enable full integer quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Force all ops to be int8\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "# Convert\n",
    "tflite_int8_model = converter.convert()\n",
    "\n",
    "# Save\n",
    "with open(\"../models/model_int8.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_int8_model)\n",
    "\n",
    "print(\" INT8 Quantized TFLite model saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
