import streamlit as st
import numpy as np
import tensorflow as tf
import cv2
import joblib
from pathlib import Path

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Streamlit Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ISL Translator", layout="wide")
st.title("ğŸ¤Ÿ ISL Real-Time Sign Language Translator")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Load TFLite Model & Labels â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
project_root = Path(__file__).resolve().parent.parent
model_path = project_root / "models" / "best_model.tflite"
label_encoder_path = project_root / "logs" / "label_encoder.pkl"

interpreter = tf.lite.Interpreter(model_path=str(model_path))
interpreter.allocate_tensors()
label_encoder = joblib.load(label_encoder_path)

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Sidebar Controls â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.header("ğŸ”§ Controls")
camera_index = st.sidebar.selectbox("Select Camera", options=[0, 1, 2], index=0)
start_camera = st.sidebar.checkbox("ğŸ“· Start Camera")
enable_tts = st.sidebar.checkbox("ğŸ”Š Enable Text-to-Speech")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Webcam & UI Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
frame_window = st.empty()
prediction_text = st.empty()  # ğŸ‘ˆ NEW: to show prediction on main UI

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Session State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "last_label" not in st.session_state:
    st.session_state["last_label"] = ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Frame Preprocessing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def preprocess_frame(frame):
    img = cv2.resize(frame, (64, 64))
    img = img.astype("float32") / 255.0
    return np.expand_dims(img, axis=0)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Prediction Function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def predict_from_frame(frame):
    img = preprocess_frame(frame)
    interpreter.set_tensor(input_details[0]['index'], img)
    interpreter.invoke()
    preds = interpreter.get_tensor(output_details[0]['index'])[0]
    pred_index = np.argmax(preds)
    label = label_encoder.inverse_transform([pred_index])[0]
    confidence = float(preds[pred_index])
    return label, confidence

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Webcam Loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if start_camera:
    cap = cv2.VideoCapture(camera_index)

    if not cap.isOpened():
        st.error("âŒ Failed to access camera.")
    else:
        st.success("âœ… Camera started. Uncheck box to stop.")

    while cap.isOpened() and start_camera:
        ret, frame = cap.read()
        if not ret:
            st.warning("âš ï¸ Could not read frame.")
            break

        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        label, confidence = predict_from_frame(frame_rgb)

        # Show webcam frame
        frame_window.image(frame_rgb)

        # âœ… Show prediction on main screen (NEW!)
        prediction_text.markdown(
            f"<h3>ğŸ§  Interpreted Sign: <span style='color:#007ACC;'>{label}</span></h3>"
            f"<h4>Confidence: <span style='color:#444;'>{confidence:.2f}</span></h4>",
            unsafe_allow_html=True
        )

        # Show prediction in sidebar
        st.sidebar.markdown(f"**Predicted Label:** `{label}`")
        st.sidebar.markdown(f"**Confidence:** `{confidence:.2f}`")

        # ğŸ”Š Speak only if label changed and confidence is high
        if enable_tts and confidence > 0.90 and label != st.session_state["last_label"]:
            try:
                import pyttsx3
                engine = pyttsx3.init()
                engine.setProperty('rate', 150)
                engine.say(f"The sign is {label}")
                engine.runAndWait()
                st.session_state["last_label"] = label
            except Exception as e:
                st.warning(f"TTS failed: {e}")

    cap.release()
    st.success("ğŸ›‘ Camera stopped.")
